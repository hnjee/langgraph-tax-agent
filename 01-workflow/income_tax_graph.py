# %%
from dotenv import load_dotenv

load_dotenv()

# %%
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(model='text-embedding-3-large')

# ê¸°ì¡´ì— ìƒì„±í•œ vector store ë¶ˆëŸ¬ì˜¤ê¸° 
vector_store = Chroma(
    embedding_function=embeddings,
    collection_name = 'income_tax_collection',
    persist_directory = '../income_tax_collection' #ë¡œì»¬ì— ì˜êµ¬ ì €ì¥ ë²„ì „ 
)

# %%
retriever = vector_store.as_retriever(search_kwargs={'k': 3})

# %%
# State ì •ì˜ 
from typing import Literal
from typing_extensions import List, TypedDict
from langchain_core.documents import Document

RELEVANCE_LITERAL = Literal["relevant", "irrelevant"]
HALLUCINATION_LITERAL = Literal["grounded", "hallucinated"]
HELPFULNESS_LITERAL = Literal["helpful", "unhelpful"] 

class AgentState(TypedDict):
    query: str
    context: List[Document]
    answer: str

    # ê²€ì¦ ê²°ê³¼ 
    doc_relevance_status: RELEVANCE_LITERAL
    hallucination_status: HALLUCINATION_LITERAL
    helpfulness_status: HELPFULNESS_LITERAL
    web_relevance_status: RELEVANCE_LITERAL

    # ê²€ì¦ ì‹œë„ íšŸìˆ˜ 
    rewrite_count: int      # ì§ˆë¬¸ ì¬ì‘ì„± ì‹œë„ íšŸìˆ˜ 
    generation_count: int   # LLM ë‹µë³€ ìƒì„± ì‹œë„ íšŸìˆ˜ 
    web_search_count: int  # ì›¹ ê²€ìƒ‰ ì‹œë„ íšŸìˆ˜ \

# %%
# Node ì •ì˜
# ì‚¬ìš©ì queryë¡œ vector storeì—ì„œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë…¸ë“œ 
def retrieve(state: AgentState) -> AgentState:
    query = state.get('query', '')
    
    docs = retriever.invoke(query)

    return {'context': docs}

# %%
from langchain_openai import ChatOpenAI
from langsmith import Client

llm = ChatOpenAI(model='gpt-4o-mini')
client = Client()

# %%
# contextì™€ queryë¥¼ ë°›ì•„ì„œ LLM ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë…¸ë“œ 
def generate(state: AgentState) -> AgentState:
    context = state.get('context', [])
    query = state.get('query', '')
    
    prompt = client.pull_prompt("rlm/rag-prompt")
    rag_chain = prompt | llm
    response = rag_chain.invoke({'question': query, 'context': context})

    return {'answer': response.content, 'generation_count': state.get('generation_count', 0) + 1}

# %%
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ê²€ìƒ‰ ê²°ê³¼ì˜ ì •í™•ë„ë¥¼ ë†’ì´ë„ë¡ ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë³€í™˜í•˜ëŠ” ë…¸ë“œ 
def rewrite(state: AgentState) -> AgentState:
    query = state.get('query', '')
    dictionary = ["ì‚¬ëŒì„ ë‚˜íƒ€ë‚´ëŠ” í‘œí˜„ -> ê±°ì£¼ì"]

    keyword_dictionary_prompt = PromptTemplate.from_template(
        f"""ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³´ê³ , í‚¤ì›Œë“œ ì‚¬ì „ì„ ì°¸ê³ í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•´ì£¼ì„¸ìš”. 
        ì‚¬ì „: {dictionary}
        ì‚¬ìš©ìì˜ ì§ˆë¬¸: {{question}}
        """
    )
    keyword_dictionary_chain = keyword_dictionary_prompt| llm | StrOutputParser()
    rewritten_query = keyword_dictionary_chain.invoke({'question': query})

    return {'query': rewritten_query, 'rewrite_count': state.get('rewrite_count', 0) + 1}

# %%
validation_llm = ChatOpenAI(model="gpt-4o", temperature=0)

# %%
def check_relevance(query, context):
    doc_relevance_prompt = client.pull_prompt("rlm/rag-document-relevance")

    doc_relevance_chain = doc_relevance_prompt | validation_llm

    response = doc_relevance_chain.invoke({
        "input": {
            "question": query,
            "documents": context
        }
    })
    
    # doc_relevance_chainì˜ ê²°ê³¼: ë¬¸ì„œ ê´€ë ¨ì„±ì´ ë†’ìœ¼ë©´ 1, ì•„ë‹ˆë©´ 0 
    if response['Score'] == 1:
        return "relevant"
    else:
        return "irrelevant"

# %%
# retriverì—ì„œ ê²€ìƒ‰í•œ ë¬¸ì„œì˜ ê´€ë ¨ì„±ì„ íŒë‹¨í•˜ëŠ” ë…¸ë“œ 
def check_doc_relevance(state: AgentState):
    query = state.get('query', '')
    context = state.get('context', [])

    result = check_relevance(query, context)

    return {"doc_relevance_status": result}

def route_after_doc_relevance(state: AgentState):
    result = state.get("doc_relevance_status", "irrelevant")
    if(result == "relevant"):
        return "generate"
    else:
        if(state.get('rewrite_count', 0) >= 2): # 2ë²ˆ ì¬ì‘ì„±í–ˆëŠ”ë°ë„ "irrelevant"ë©´ ì›¹ ê²€ìƒ‰ 
            return "web_search_rewrite"
        else:
            return "rewrite"

# %%
# í• ë£¨ì‹œë„¤ì´ì…˜ ê²€ì¦ ë…¸ë“œ  
def check_hallucination(state: AgentState):
    context = state.get("context", [])
    answer = state.get("answer", "")

    hallucination_prompt = PromptTemplate.from_template("""
        ë‹¹ì‹ ì€ í•™ìƒì˜ ë‹µë³€ì´ ì œê³µëœ ë¬¸ì„œì— ê¸°ë°˜í–ˆëŠ”ì§€ í‰ê°€í•˜ëŠ” ì„ ìƒë‹˜ì…ë‹ˆë‹¤.
        ì†Œë“ì„¸ë²•ì—ì„œ ë°œì·Œí•œ ë¬¸ì„œë“¤ê³¼ í•™ìƒì˜ ë‹µë³€ì´ ì£¼ì–´ì§‘ë‹ˆë‹¤.
        í•™ìƒì˜ ë‹µë³€ì´ ë¬¸ì„œì— ê¸°ë°˜í•œ ê²½ìš° "grounded"ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
        í•™ìƒì˜ ë‹µë³€ì´ ë¬¸ì„œì— ê¸°ë°˜í•˜ì§€ ì•Šì€ ê²½ìš° "hallucinated"ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
        ë‹¨, í•™ìƒì´ "ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤", "ë¬¸ì„œì— í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤" ë“±ìœ¼ë¡œ ì†”ì§í•˜ê²Œ ë‹µë³€í•œ ê²½ìš°ì—ë„ "grounded"ë¡œ íŒë‹¨í•˜ì„¸ìš”.

        ë¬¸ì„œ: {documents}
        í•™ìƒì˜ ë‹µë³€: {student_answer}
        """
    )

    hallucinations_chain = hallucination_prompt | validation_llm | StrOutputParser()
    
    # í‰ê°€ ì‹¤í–‰
    response = hallucinations_chain.invoke({
        "documents": context,
        "student_answer": answer 
    })

    # íŒë‹¨ ê²°ê³¼ë¥¼ Stateì— ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    return {"hallucination_status": response}

def route_after_hallucination(state: AgentState):
    result = state.get("hallucination_status", "hallucinated")
    if(result == "grounded"):
        return "check_helpfulness"
    else:
        if(state.get('generation_count', 0) >= 4): # 3ë²ˆ ì¬ìƒì„±í–ˆëŠ”ë°ë„ "hallucinated"ë©´ ë‹µë³€ ì‘ì„± ì‹¤íŒ¨ (ì´ˆê¸° 1ë²ˆì€ ì¬ìƒì„±ì´ ì•„ë‹ˆë¯€ë¡œ ì œì™¸)
            return "inform_failure"
        else:
            return "generate"

# %%
# ìœ ìš©ì„± ê²€ì¦ ë…¸ë“œ 
from langgraph.graph import END

def check_helpfulness(state:AgentState):
    query = state.get('query', '')
    answer = state.get('answer', '')

    # Hubì—ì„œ ê²€ì¦ëœ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
    helpfulness_prompt = client.pull_prompt("rlm/rag-answer-helpfulness")

    helpfulness_chain = helpfulness_prompt | validation_llm
    
    # í‰ê°€ ì‹¤í–‰
    response = helpfulness_chain.invoke({
        "input": {
            "question": query  
        },
        "output": answer 
    })
    
    score = response["Score"]
    if(score == 1):
        return {"helpfulness_status": "helpful"}
    else:
        return {"helpfulness_status": "unhelpful"}

def route_after_helpfulness(state: AgentState):
    result = state.get("helpfulness_status", "unhelpful")
    if(result == "helpful"):
        return "helpful"
    else:
        if(state.get('web_search_count', 0) == 0):
            return "web_search_rewrite"
        else:
            return "inform_failure"

# %%

def inform_failure(state: AgentState) -> AgentState:
    # ê¸°ì¡´ì— ìƒì„±ë˜ì—ˆë˜ ë‹µë³€(ì •ì§í•œ ê±°ì ˆ ë‹µë³€ ë“±)ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    existing_answer = state.get("answer", "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì‹¤íŒ¨ ì•ˆë‚´ ë©”ì‹œì§€ë¥¼ ì¡°ê¸ˆ ë” ì „ë¬¸ì ìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.
    failure_message = (
        f"--- [ìµœì¢… í™•ì¸ ê²°ê³¼] ---\n"
        f"{existing_answer}\n\n"
        f"------------------------\n"
        f"ğŸ’¡ ì•ˆë‚´: ë‚´ë¶€ ë¬¸ì„œë¥¼ í™•ì¸í–ˆìœ¼ë‚˜ ì§ˆë¬¸ì— ëŒ€í•œ ë” êµ¬ì²´ì ì¸ í™•ë‹µì„ ë“œë¦¬ê¸° ì–´ë ¤ìš´ ìƒíƒœì…ë‹ˆë‹¤. "
        f"ì§ˆë¬¸ì„ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ(ì˜ˆ: ì—°ë„, íŠ¹ì • ìƒí™© ë“±) ë°”ê¿”ì„œ ë‹¤ì‹œ ë¬¼ì–´ë´ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤."
    )
    
    return {"answer": failure_message}

# %%
# ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ì›¹ ê²€ìƒ‰ì— ì í•©í•˜ë„ë¡ ë³€í™˜í•˜ëŠ” ë…¸ë“œ 
def web_search_rewrite(state: AgentState) -> AgentState:
    query = state.get('query', '') #ì‚¬ìš©ì ì›ë³¸ ì§ˆë¬¸ ì‚¬ìš© 
    
    web_search_rewrite_prompt = PromptTemplate.from_template(
        f""" ì•„ë˜ ì§ˆë¬¸ì„ ì›¹ ê²€ìƒ‰ì—ì„œ ê°€ì¥ ìµœì‹ ì˜ ì •í™•í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ” ê²€ìƒ‰ì–´ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”. 
        ì§ˆë¬¸: {query}
        """
    )
    web_search_rewrite_chain = web_search_rewrite_prompt | llm | StrOutputParser()
    rewritten_query = web_search_rewrite_chain.invoke({'query': query})

    return {'query': rewritten_query, 'generation_count': 0} # ì›¹ ê²€ìƒ‰ ì¬ì‘ì„±ì„ ìœ„í•´ generation ì¹´ìš´íŠ¸ ì´ˆê¸°í™”

# %%
from langchain_tavily import TavilySearch

tavily_search_tool = TavilySearch(
    max_results=3, # ë””í´íŠ¸ 5 
    search_depth="advanced" # ë””í´íŠ¸ "basic"
)

# %%
#web_results = tavily_search_tool.invoke("ë´‰ì²œë™ ì–‘ê¼¬ì¹˜ ë§›ì§‘ ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ ë¸”ë¡œê·¸ í¬ìŠ¤íŒ… ë§› í‰ê°€")
#print(web_results)

# %%
def web_search(state: AgentState) -> AgentState:
    # 1. ê¸°ì¡´ context ê°€ì ¸ì˜¤ê¸°
    existing_context = state.get('context', [])
    
    # 2. ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ 
    query = state.get('query', '')
    web_results = tavily_search_tool.invoke(query)
    
    # 3. ê²€ìƒ‰ ê²°ê³¼ë¥¼ metadataê°€ í¬í•¨ëœ Document ê°ì²´ë¡œ ë³€í™˜
    new_docs = []
    for result in web_results["results"]:
        full_content = f"ì œëª©: {result.get('title', '')}\në‚´ìš©: {result.get('content', '')}"
        doc = Document(
            page_content=full_content,
            metadata={
                "category": "web_search", 
                "source": result.get("url", "unknown"),
                "score": result.get("score", 0)
            }
        )
        new_docs.append(doc)
    
    # 4. ê¸°ì¡´ context ë’¤ì— ìƒˆ ì •ë³´ ë¶™ì´ê¸°
    return {"context": existing_context + new_docs, 'web_search_count': state.get('web_search_count', 0) + 1}

# %%
def check_web_relevance(state: AgentState):
    context = state.get('context', [])
    query = state.get('query', '')
    
    result = check_relevance(query, context)

    return {"web_relevance_status": result}

def route_after_web_relevance(state: AgentState):
    status = state.get("web_relevance_status", "irrelevant")
    
    if status == "relevant":
        return "generate"        
    else:
        return "inform_failure"  #ì›¹ ê²€ìƒ‰ ì¬ì‹œë„ ì•ˆí•¨ 

# %%
from langchain_core.prompts import ChatPromptTemplate


def query_router(state: AgentState) -> Literal['vector_store', 'llm', 'web_search']:
    query = state.get('query', '')

    query_router_system_prompt = """
    ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ 'vector_store','web_search', ë˜ëŠ” 'basic_generate'ë¡œ ë¼ìš°íŒ…í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì•„ë˜ì˜ ì„¤ëª…ì„ ë³´ê³  ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ê°€ì¥ ì ì ˆí•œ ê²½ë¡œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.
    1. 'vector_store'ëŠ” 2024ë…„ 12ì›”ê¹Œì§€ì˜ ì†Œë“ì„¸ ê´€ë ¨ ì •ë³´ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì†Œë“ì„¸ ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” 'vector_store'ë¥¼ ì„ íƒí•˜ì„¸ìš”. 
    2. ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•˜ë‹¤ê³  ìƒê°ë˜ë©´ 'web_search'ë¥¼ ì„ íƒí•˜ì„¸ìš”. ì§ˆë¬¸ì´ ì†Œë“ì„¸ ê´€ë ¨ ì§ˆë¬¸ì´ì§€ë§Œ, 2024ë…„ 12ì›” ì´í›„ì˜ ìµœê·¼ ì •ë³´ë¥¼ í•„ìš”ë¡œ í•˜ëŠ” ê²½ìš°ì—ëŠ” 'web_search'ë¥¼ ì„ íƒí•˜ì„¸ìš”. 
    3. ì§ˆë¬¸ì´ ì¶©ë¶„íˆ ì‰¬ìš´ ì§ˆë¬¸ì´ë©´ 'basic_generate'ì„ ì„ íƒí•˜ì„¸ìš”. 
    ì¤‘ìš”: ë‹µë³€ì€ ë¬´ì¡°ê±´ vector_store, web_search, basic_generate ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì •í™•íˆ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¬¸ì¥ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
    """

    query_router_prompt = ChatPromptTemplate.from_messages([
        ("system", query_router_system_prompt),
        ("user", "{query}")
    ])

    query_router_chain = query_router_prompt | llm | StrOutputParser()

    route = query_router_chain.invoke({'query': query})

    return route


# %%
def basic_generate(state: AgentState) -> AgentState:
    query = state.get('query', '')
    response = llm.invoke(query)
    return {'answer': response.content}

# %%
from langgraph.graph import StateGraph, START, END

#  ê·¸ë˜í”„ ë¹Œë” ìƒì„± 
graph_builder = StateGraph(AgentState)

# ë…¸ë“œ ì¶”ê°€ 
graph_builder.add_node("retrieve", retrieve)
graph_builder.add_node("generate", generate)
graph_builder.add_node("rewrite", rewrite)
graph_builder.add_node("check_doc_relevance", check_doc_relevance)
graph_builder.add_node("check_hallucination", check_hallucination)
graph_builder.add_node("check_helpfulness", check_helpfulness)
graph_builder.add_node("inform_failure", inform_failure)

graph_builder.add_node("web_search_rewrite", web_search_rewrite)
graph_builder.add_node("web_search", web_search)
graph_builder.add_node("check_web_relevance", check_web_relevance)

graph_builder.add_node("basic_generate", basic_generate)


# %%
from langgraph.graph import START, END
# ì—£ì§€ ì¶”ê°€ 
graph_builder.add_conditional_edges(
    START,
    query_router,
    {
        "vector_store": "retrieve",
        "web_search": "web_search_rewrite",
        "basic_generate": "basic_generate"
    }
)
graph_builder.add_edge("retrieve", "check_doc_relevance")
graph_builder.add_conditional_edges(
    "check_doc_relevance", 
    route_after_doc_relevance,
    {
        "generate": "generate", #relevant
        "rewrite": "rewrite", #irrelevant
        "web_search_rewrite": "web_search_rewrite" # 2ë²ˆ ì¬ì‘ì„± + irrelevant 
    }
)
graph_builder.add_edge('rewrite', 'retrieve')
graph_builder.add_edge("generate", "check_hallucination")
graph_builder.add_conditional_edges(
    "check_hallucination", 
    route_after_hallucination,
    {
        "check_helpfulness": "check_helpfulness", #grounded
        "generate": "generate", #hallucinated
        "inform_failure": "inform_failure" # 3ë²ˆ ì¬ìƒì„± + hallucinated
    }
)
graph_builder.add_conditional_edges(
    "check_helpfulness",
    route_after_helpfulness,
    {   "helpful": END, #helpful
        "web_search_rewrite": "web_search_rewrite", # ì›¹ ê²€ìƒ‰ ì‹œë„ 0íšŒ + unhelpful
        "inform_failure": "inform_failure" # ì›¹ ê²€ìƒ‰ ì‹œë„ 1íšŒ ì´ìƒ + unhelpful
    }
)
graph_builder.add_edge("web_search_rewrite", "web_search")
graph_builder.add_edge("web_search", "check_web_relevance")
graph_builder.add_conditional_edges(
    "check_web_relevance",
    route_after_web_relevance,
    {
        "generate": "generate", #relevant
        "inform_failure": "inform_failure" #irrelevant
    }
)

graph_builder.add_edge("inform_failure", END)
graph_builder.add_edge("basic_generate", END)

# %%
# ê·¸ë˜í”„ ìƒì„± 
graph = graph_builder.compile() 

