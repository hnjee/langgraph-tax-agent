{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84aa6d1a",
   "metadata": {},
   "source": [
    "## LangChain으로 Tool 사용하기 \n",
    "\n",
    "### 1. 도구 정의 (Tool Definition)\n",
    "- 핵심: `@tool` 데코레이터를 사용해 일반 파이썬 함수를 랭체인 도구로 변환합니다.\n",
    "- Docstring의 역할: LLM은 파이썬 코드를 읽는 게 아니라 **함수 설명 Docstring**을 읽고 \"이 도구가 무슨 일을 하는지\" 판단합니다. 설명이 부실하면 LLM이 도구를 선택하지 못합니다.\n",
    "- 타입 힌트: a: int와 같은 타입 지정은 LLM이 인자(args)를 어떤 자료형으로 넘겨줄지 결정하는 기준이 됩니다.\n",
    "\n",
    "### 2. 도구 바인딩 (Binding Tools)\n",
    "- 메서드: llm_with_tools = `llm.bind_tools([함수명])`\n",
    "- 내부 동작: 랭체인은 우리가 정의한 함수를 JSON Schema 형태로 변환합니다. 이 스키마에는 함수의 이름, 설명, 필요한 파라미터 정보가 포함됩니다.\n",
    "- 연결 의미: LLM 객체에게 \"너는 대답하기 전에 이 도구 목록(JSON)을 참고해서, 필요하면 나에게 실행을 요청해!\"라고 가이드를 전달하는 설정입니다.\n",
    "\n",
    "### 3. 호출 및 판단 (Invoke & Reasoning)\n",
    "- 과정: `llm_with_tools.invoke(\"질문\")` 호출 시, 질문과 함께 **도구 명세서 JSON**가 모델 API로 전송됩니다.\n",
    "- LLM의 판단: 모델은 질문을 분석한 뒤, 직접 답할지 아니면 도구를 쓸지 결정합니다.\n",
    "- 반환값 (AI Message)\n",
    "    - 도구를 사용하기로 결정한 경우: content는 비우고 tool_calls에 실행할 도구의 이름(name), 입력값(args), 고유 ID가 담긴 리스트를 채워서 반환함 \n",
    "    - 도구를 사용하지 않고 직접 답하기로 결정한 경우: tool_calls에는 비우고, content에 답변을 직접 채워서 반환함 \n",
    "- 반드시 도구를 하나라도 사용하도록 강제하는 설정도 존재함 \n",
    "    - llm_forced_to_calc = small_llm.bind_tools([add, multiply], tool_choice=\"required\")\n",
    "\n",
    "### 4. 실행 및 최종 답변 (Execution & Final Response)\n",
    "- 도구 실행: LLM이 제안한 tool_calls 정보를 바탕으로 실제 파이썬 함수를 실행합니다.\n",
    "- ToolMessage 생성: 도구 실행 결과값(content)과 함께, 반드시 LLM이 부여했던 **고유 ID(tool_call_id)**를 매칭하여 메시지를 생성합니다.\n",
    "- 컨텍스트 완성: [사용자 질문, LLM의 도구 호출 제안, 실제 도구 실행 결과] 세 가지 메시지를 리스트로 묶어 다시 LLM을 호출합니다.\n",
    "- 최종 답변: 모든 정보를 전달받은 LLM은 비로소 tool_calls 대신 content에 최종 답변을 채워서 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a4c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOOL 함수의 정보를 LLM에게 전달하는 도구 명세서 JSON 예시    \n",
    "{\n",
    "  \"name\": \"add\",\n",
    "  \"description\": \"숫자 a와 b를 더합니다.\",  # <--- 바로 여기가 Docstring 내용!\n",
    "  \"parameters\": {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"a\": {\"type\": \"integer\"},\n",
    "      \"b\": {\"type\": \"integer\"}\n",
    "    },\n",
    "    \"required\": [\"a\", \"b\"]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14c3d892",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "#이 함수가 도구(tool)라는 것을 알려주기 위한 어노테이션\n",
    "@tool \n",
    "#@tool(args_schema=MyInputSchema, description=\"여기에 설명을 적어도 됩니다\")\n",
    "def add(a: int, b:int) -> int:\n",
    "    # LangChain의 @tool 데코레이터는 함수에 docstring(함수에 대한 설명 주석)이 필요합니다. \n",
    "    # docstring이 없으면 description 파라미터를 제공해야 합니다.\n",
    "    \"\"\"숫자 a와 b를 더합니다.\"\"\" \n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b:int) -> int:\n",
    "    \"\"\"숫자 a와 b를 곱합니다.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d949c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add 실행됩니다\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tool로 정의한 함수 호출 방법 \n",
    "#add(4, 8) #에러 \n",
    "add.invoke({'a': 4, 'b': 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddcdd655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "small_llm = ChatOpenAI(model='gpt-4o')\n",
    "#small_llm = ChatOpenAI(model='gpt-4o-mini')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ad9735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bind_tools: \"이 LLM 객체가 호출될 때, 사용할 수 있는 도구들의 명세서(Blueprint)를 함께 전달하도록 세팅하는 것\"\n",
    "# 동작 원리: small_llm.bind_tools([add, multiply])를 하면, 내부적으로는 우리가 만든 파이썬 함수를 JSON Schema라는 규격으로 변환합니다.\n",
    "# 고정된 연결: 이제 llm_with_tools 객체를 사용할 때마다, 랭체인은 모델(GPT-4o-mini 등)에게 \"너는 대답할 때 이 도구 명세서들을 참고해서, 필요하면 이 함수를 쓰겠다고 말해줘\"라고 매번 알려주는 상태가 된 것입니다.\n",
    "llm_with_tools = small_llm.bind_tools([add, multiply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d2d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"3 곱하기 5는?\"\n",
    "small_llm.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14bdfbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"3 곱하기 5는?\" # tool_calls에 multiply 함수 채워서 반환  \n",
    "# query = \"미국의 수도는?\" #답변을 content에 직접 반환 \n",
    "ai_message = llm_with_tools.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd41b5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAIMessage(\\ncontent='',\\nadditional_kwargs={\\n  'refusal': None\\n},\\nresponse_metadata={\\n  'token_usage': {\\n    'completion_tokens': 17,\\n    'prompt_tokens': 84,\\n    'total_tokens': 101,\\n    'completion_tokens_details': {\\n      'accepted_prediction_tokens': 0,\\n      'audio_tokens': 0,\\n      'reasoning_tokens': 0,\\n      'rejected_prediction_tokens': 0\\n    },\\n    'prompt_tokens_details': {\\n      'audio_tokens': 0,\\n      'cached_tokens': 0\\n    }\\n  },\\n  'model_provider': 'openai',\\n  'model_name': 'gpt-4o-mini-2024-07-18',\\n  'system_fingerprint': 'fp_084a28d6e8',\\n  'id': 'chatcmpl-DAthPuDctj6Ez2GrnMp2VVIsYCGNK',\\n  'service_tier': 'default',\\n  'finish_reason': 'tool_calls',\\n  'logprobs': None\\n},\\nid='lc_run--019c7504-8e08-75e2-b032-89488e048821-0',\\ntool_calls=[\\n  {\\n    'name': 'multiply',\\n    'args': {\\n      'a': 3,\\n      'b': 5\\n    },\\n    'id': 'call_PXganPzH2xzknY73JSiSRlBE',\\n    'type': 'tool_call'\\n  }\\n],\\ninvalid_tool_calls=[\\n\\n],\\nusage_metadata={\\n  'input_tokens': 84,\\n  'output_tokens': 17,\\n  'total_tokens': 101,\\n  'input_token_details': {\\n    'audio': 0,\\n    'cache_read': 0\\n  },\\n  'output_token_details': {\\n    'audio': 0,\\n    'reasoning': 0\\n  }\\n})\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message\n",
    "\n",
    "'''\n",
    "AIMessage(\n",
    "content='',\n",
    "additional_kwargs={\n",
    "  'refusal': None\n",
    "},\n",
    "response_metadata={\n",
    "  'token_usage': {\n",
    "    'completion_tokens': 17,\n",
    "    'prompt_tokens': 84,\n",
    "    'total_tokens': 101,\n",
    "    'completion_tokens_details': {\n",
    "      'accepted_prediction_tokens': 0,\n",
    "      'audio_tokens': 0,\n",
    "      'reasoning_tokens': 0,\n",
    "      'rejected_prediction_tokens': 0\n",
    "    },\n",
    "    'prompt_tokens_details': {\n",
    "      'audio_tokens': 0,\n",
    "      'cached_tokens': 0\n",
    "    }\n",
    "  },\n",
    "  'model_provider': 'openai',\n",
    "  'model_name': 'gpt-4o-mini-2024-07-18',\n",
    "  'system_fingerprint': 'fp_084a28d6e8',\n",
    "  'id': 'chatcmpl-DAthPuDctj6Ez2GrnMp2VVIsYCGNK',\n",
    "  'service_tier': 'default',\n",
    "  'finish_reason': 'tool_calls',\n",
    "  'logprobs': None\n",
    "},\n",
    "id='lc_run--019c7504-8e08-75e2-b032-89488e048821-0',\n",
    "tool_calls=[\n",
    "  {\n",
    "    'name': 'multiply',\n",
    "    'args': {\n",
    "      'a': 3,\n",
    "      'b': 5\n",
    "    },\n",
    "    'id': 'call_PXganPzH2xzknY73JSiSRlBE',\n",
    "    'type': 'tool_call'\n",
    "  }\n",
    "],\n",
    "invalid_tool_calls=[\n",
    "  \n",
    "],\n",
    "usage_metadata={\n",
    "  'input_tokens': 84,\n",
    "  'output_tokens': 17,\n",
    "  'total_tokens': 101,\n",
    "  'input_token_details': {\n",
    "    'audio': 0,\n",
    "    'cache_read': 0\n",
    "  },\n",
    "  'output_token_details': {\n",
    "    'audio': 0,\n",
    "    'reasoning': 0\n",
    "  }\n",
    "})\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1619ef4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 3, 'b': 5},\n",
       "  'id': 'call_kFNflk7yQdIiTR5M56SpwN8K',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message.tool_calls # 리스트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29d54519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'add',\n",
       " 'args': {'a': 3, 'b': 5},\n",
       " 'id': 'call_PRApXsBflPoh38dNtuXQk55s',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 메시지에서 도구 호출 정보 추출\n",
    "tool_call = ai_message.tool_calls[0] # 첫 번째 제안 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7afe8cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='15', name='multiply', tool_call_id='call_kFNflk7yQdIiTR5M56SpwN8K')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 직접 함수 실행 (이때 tool_call 정보를 통째로 넘김)\n",
    "tool_message = multiply.invoke(tool_call) # args라는 키의 값에서 a와 b 값만 알아서 추출해서 실제 함수에 넣어줌 \n",
    "tool_message # 결과는 ToolMessage 형태로 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0f5fa5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='3 곱하기 5는?', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from langchain_core.messages import AnyMessage, HumanMessage\n",
    "\n",
    "human_message = HumanMessage(query) # \"3 곱하기 5는?\" \n",
    "human_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228b20a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 이 메시지를 다시 메시지 리스트에 수동으로 append\n",
    "message_list: Sequence[AnyMessage] = [human_message] # 사용자 질문 \n",
    "\n",
    "message_list.append(ai_message) # 사용할 tool \n",
    "\n",
    "message_list.append(tool_message) # tool을 사용해서 나온 결과 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46703ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='3 곱하기 5는?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 84, 'total_tokens': 101, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_64dfa806c7', 'id': 'chatcmpl-DCKZq9eGJ2ICllPBjZog0hBiHz8wD', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c8961-a9a4-7692-ac0d-39914b7bf287-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 5}, 'id': 'call_kFNflk7yQdIiTR5M56SpwN8K', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 84, 'output_tokens': 17, 'total_tokens': 101, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='15', name='multiply', tool_call_id='call_kFNflk7yQdIiTR5M56SpwN8K')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaf74e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm_with_tools.invoke(message_list) #모든 컨텍스트를 전달받은 LLM은 최종 답변을 content에 넣어 반환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2858aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='3 곱하기 5는 15입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 109, 'total_tokens': 121, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_01cbaa0587', 'id': 'chatcmpl-DCKqm06SuZcZqxDFdCtJST12FlmHg', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c8971-b340-7653-bb09-82862f8cd26d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 109, 'output_tokens': 12, 'total_tokens': 121, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result \n",
    "'''\n",
    "(content='3 곱하기 5는 15입니다.',\n",
    "additional_kwargs={\n",
    "  'refusal': None\n",
    "},\n",
    "response_metadata={\n",
    "  'token_usage': {\n",
    "    'completion_tokens': 12,\n",
    "    'prompt_tokens': 109,\n",
    "    'total_tokens': 121,\n",
    "    'completion_tokens_details': {\n",
    "      'accepted_prediction_tokens': 0,\n",
    "      'audio_tokens': 0,\n",
    "      'reasoning_tokens': 0,\n",
    "      'rejected_prediction_tokens': 0\n",
    "    },\n",
    "    'prompt_tokens_details': {\n",
    "      'audio_tokens': 0,\n",
    "      'cached_tokens': 0\n",
    "    }\n",
    "  },\n",
    "  'model_provider': 'openai',\n",
    "  'model_name': 'gpt-4o-2024-08-06',\n",
    "  'system_fingerprint': 'fp_01cbaa0587',\n",
    "  'id': 'chatcmpl-DCKqm06SuZcZqxDFdCtJST12FlmHg',\n",
    "  'service_tier': 'default',\n",
    "  'finish_reason': 'stop',\n",
    "  'logprobs': None\n",
    "},\n",
    "id='lc_run--019c8971-b340-7653-bb09-82862f8cd26d-0',\n",
    "tool_calls=[\n",
    "  \n",
    "],\n",
    "invalid_tool_calls=[\n",
    "  \n",
    "],\n",
    "usage_metadata={\n",
    "  'input_tokens': 109,\n",
    "  'output_tokens': 12,\n",
    "  'total_tokens': 121,\n",
    "  'input_token_details': {\n",
    "    'audio': 0,\n",
    "    'cache_read': 0\n",
    "  },\n",
    "  'output_token_details': {\n",
    "    'audio': 0,\n",
    "    'reasoning': 0\n",
    "  }\n",
    "})\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
